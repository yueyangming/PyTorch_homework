{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://wiki.swarma.net/images/e/e7/集智AI学园首页左上角logo_2017.8.17.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 火炬上的深度学习（下）第三节：神经网络莫扎特"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 课后作业：使用 LSTM 编写一个国际姓氏生成模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在火炬课程中，我们学习了使用 LSTM 来生成 MIDI 音乐。这节课我们使用类似的方法，再创建一个 LSTM 国际起名大师！\n",
    "\n",
    "完成后的模型能够像下面这样使用，指定一个国家名，模型即生成几个属于这个国家的姓氏。\n",
    "\n",
    "```\n",
    "> python generate.py Russian\n",
    "Rovakov    Uantov    Shavakov\n",
    "\n",
    "> python generate.py German\n",
    "Gerren    Ereng    Rosher\n",
    "\n",
    "> python generate.py Spanish\n",
    "Salla    Parer    Allan\n",
    "\n",
    "> python generate.py Chinese\n",
    "Chan    Hang    Iun\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 第一步当然是引入PyTorch及相关包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "这次的数据仍然是18个文本文件，每个文件以“国家名字”命名，文件中存储了大量这个国家的姓氏。\n",
    "\n",
    "在读取这些数据前，为了简化神经网络的输入参数规模，我们把各国各语言人名都转化成用26个英文字母来表示，下面就是转换的方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "6a9d80df-1d38-4c41-849c-95e38da98cc7"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O'Neal\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "# all_letters 即课支持打印的字符+标点符号\n",
    "all_letters = string.ascii_letters + \" .,;'-\"\n",
    "# Plus EOS marker\n",
    "n_letters = len(all_letters) + 1 \n",
    "EOS = n_letters - 1\n",
    "\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "print(unicode_to_ascii(\"O'Néàl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到 `\"O'Néàl\"` 被转化成了以普通ASCII字符表示的 `O'Neal`。\n",
    "\n",
    "在上面的代码中，还要注意这么几个变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_letters:  abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .,;'-\n",
      "n_letters:  59\n",
      "EOS:  58\n"
     ]
    }
   ],
   "source": [
    "# 姓氏中所有的可视字符\n",
    "print('all_letters: ', all_letters)\n",
    "# 所有字符的长度 +1 EOS结束符\n",
    "print('n_letters: ', n_letters)\n",
    "# 结束符，没有实质内容\n",
    "print('EOS: ', EOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中 `all_letters` 包含了我们数据集中所有可能出现的字符，也就是“字符表”。\n",
    "`n_letters` 是字符表的长度，在本例中长度为59。`EOS` 的索引号为58，它在字符表中没有对应的字符，仅代表结束。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备好处理数据的方法，下面就可以放心的读取数据了。\n",
    "\n",
    "我们建立一个列表 `all_categories` 用于存储所有的国家名字。\n",
    "\n",
    "建立一个字典 `category_lines`，以读取的国名作为字典的索引，国名下存储对应国别的名字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# categories:  18 ['Arabic', 'Chinese', 'Czech', 'Dutch', 'English', 'French', 'German', 'Greek', 'Irish', 'Italian', 'Japanese', 'Korean', 'Polish', 'Portuguese', 'Russian', 'Scottish', 'Spanish', 'Vietnamese']\n",
      "\n",
      "# Russian names:  ['Ababko', 'Abaev', 'Abagyan', 'Abaidulin', 'Abaidullin', 'Abaimoff', 'Abaimov', 'Abakeliya', 'Abakovsky', 'Abakshin']\n"
     ]
    }
   ],
   "source": [
    "# 按行读取出文件中的名字，并返回包含所有名字的列表\n",
    "def read_lines(filename):\n",
    "    lines = open(filename).read().strip().split('\\n')\n",
    "    return [unicode_to_ascii(line) for line in lines]\n",
    "\n",
    "\n",
    "# category_lines是一个字典\n",
    "# 其中索引是国家名字，内容是从文件读取出的这个国家的所有名字\n",
    "category_lines = {}\n",
    "# all_categories是一个列表\n",
    "# 其中包含了所有的国家名字\n",
    "all_categories = []\n",
    "# 循环所有文件\n",
    "for filename in glob.glob('./names/*.txt'):\n",
    "    # 从文件名中切割出国家名字\n",
    "    category = filename.split('/')[-1].split('.')[0].split('\\\\')[-1]\n",
    "    # 将国家名字添加到列表中\n",
    "    all_categories.append(category)\n",
    "    # 读取对应国别文件中所有的名字\n",
    "    lines = read_lines(filename)\n",
    "    # 将所有名字存储在字典中对应的国别下\n",
    "    category_lines[category] = lines\n",
    "\n",
    "# 共有的国别数\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "print('# categories: ', n_categories, all_categories)\n",
    "print()\n",
    "print('# Russian names: ', category_lines['Russian'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20074\n"
     ]
    }
   ],
   "source": [
    "# 再统计下手头共有多少条训练数据\n",
    "all_line_num = 0\n",
    "for key in category_lines:\n",
    "    all_line_num += len(category_lines[key])\n",
    "print(all_line_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们的数据准备好了，可以搭建神经网络了！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先建立一个可以随机选择数据对 `(category, line)` 的方法，以方便训练时调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Portuguese', 'Rocha')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def random_training_pair():\n",
    "    # 随机选择一个国别名\n",
    "    category = random.choice(all_categories)\n",
    "    # 读取这个国别名下的所有人名\n",
    "    line = random.choice(category_lines[category])\n",
    "    return category, line\n",
    "\n",
    "print(random_training_pair())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先处理国别，将国别名转化为索引。\n",
    "\n",
    "这个索引是要和姓氏一起传入神经网络模型的。我们这次编写的是根据“国名条件”生成“符合条件的姓氏”的 LSTM 模型。这种将“条件”和“符合条件的数据”合并一起作为训练输入数据的方法，在“条件模型”里非常流行。\n",
    "\n",
    "比如 条件GAN（Conditional GAN），在训练时是把数据标签拼接到数据图片中一起进行训练的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# 将名字所属的国家名转化为“独热向量”\n",
    "def make_category_input(category):\n",
    "    li = all_categories.index(category)\n",
    "    return  li\n",
    "\n",
    "print(make_category_input('Italian'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "对于训练过程中的每一步，或者说对于训练数据中每个名字的每个字符来说，神经网络的输入是 `(category, current letter, hidden state)`，输出是 `(next letter, next hidden state)`。\n",
    "\n",
    "与在课程中讲的一样，神经网络还是依据“当前的字符”预测“下一个字符”。比如对于“Kasparov”这个名字，创建的（input, target）数据对是 (\"K\", \"a\"), (\"a\", \"s\"), (\"s\", \"p\"), (\"p\", \"a\"), (\"a\", \"r\"), (\"r\", \"o\"), (\"o\", \"v\"), (\"v\", \"EOS\")。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "cf311809-10bf-40f7-87e1-1952342f7f35"
    }
   },
   "outputs": [],
   "source": [
    "def make_chars_input(nameStr):\n",
    "    name_char_list = list(map(lambda x: all_letters.find(x), nameStr))\n",
    "    return name_char_list\n",
    "\n",
    "\n",
    "def make_target(nameStr):\n",
    "    target_char_list = list(map(lambda x: all_letters.find(x), nameStr[1:]))\n",
    "    target_char_list.append(n_letters - 1)# EOS\n",
    "    return target_char_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样为了训练时方便使用，我们建立一个 `random_training_set` 函数，以随机选择出数据集 `(category, line)` 并转化成训练需要的 Tensor： `(category, input, target) `。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_training_set():\n",
    "    # 随机选择数据集\n",
    "    category, line = random_training_pair()\n",
    "    #print(category, line)\n",
    "    # 转化成对应 Tensor\n",
    "    category_input = make_category_input(category)\n",
    "    line_input = make_chars_input(line)\n",
    "    #category_name_input = make_category_name_input(category, line)\n",
    "    line_target = make_target(line)\n",
    "    return category_input, line_input, line_target\n",
    "    #return category_name_input, line_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, [32, 0, 18, 18], [0, 18, 18, 58])\n"
     ]
    }
   ],
   "source": [
    "print(random_training_set())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4ff5f52a-2523-47f0-beba-f6c29d412e5f"
    }
   },
   "source": [
    "# 搭建神经网络\n",
    "\n",
    "这次使用的 LSTM 神经网络整体结构上与课上讲的生成音乐的模型非常相似，不过有一点请注意一下。\n",
    "\n",
    "我们要把国别和国别对应的姓氏一同输入到神经网络中，这样 LSTM 模型才能分别学习到每个国家姓氏的特色，从而生成不同国家不同特色的姓氏。\n",
    "\n",
    "那国别数据与姓氏数据应该如何拼接哪？应该在嵌入前拼接，还是在嵌入后再进行拼接哪？嵌入后的维度与 hidden_size 有怎样的关系哪？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 你需要参考课上的模型，将这个模型补充完整。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一个手动实现的LSTM模型，\n",
    "\n",
    "class LSTMNetwork(nn.Module):\n",
    "    def __init__(self, category_size, name_size, hidden_size, output_size, num_layers = 1):\n",
    "        super(LSTMNetwork, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "       \n",
    "        # 进行嵌入\n",
    "        self.Embedding_category = nn.Embedding(category_size, hidden_size)\n",
    "        self.Embedding_name = nn.Embedding(name_size, hidden_size)\n",
    "        \n",
    "        # 隐含层内部的相互链接\n",
    "        \n",
    "        self.lstm = nn.LSTM(2 * hidden_size, hidden_size, num_layers, batch_first = True)\n",
    "        \n",
    "        self.FC = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        # 输出层\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, category_variable, name_variable, hidden):\n",
    "        \n",
    "        # 先分别进行embedding层的计算\n",
    "#         print('category_variable size', category_variable.size())\n",
    "        category_embedded = self.Embedding_category(category_variable)\n",
    "#         print('name_variable size', name_variable.size())\n",
    "        name_embedded = self.Embedding_name(name_variable)\n",
    "        \n",
    "#         print('category_embedded size before cat: ', category_embedded.size())\n",
    "#         print('name embedded size before cat:', name_embedded.size())\n",
    "        temp = torch.cat( (category_embedded, name_embedded) , 2)\n",
    "        \n",
    "#         print('temp', temp)\n",
    "        \n",
    "        output, hidden = self.lstm(temp, hidden)\n",
    "#         print('size before', output.size())\n",
    "        output = output[:,-1,:]\n",
    "        # 从输入到隐含层的计算\n",
    "#         print('size after', output.size())\n",
    "        # output的尺寸：batch_size, len_seq, hidden_size\n",
    "        \n",
    "        # 全连接层\n",
    "        output = self.FC(output)\n",
    "        # output的尺寸：batch_size, output_size\n",
    "        # softmax函数\n",
    "        output = self.softmax(output)\n",
    "#         print('before print', output.size())\n",
    "        return output, hidden\n",
    " \n",
    "    def initHidden(self):\n",
    "        # 对隐含单元的初始化\n",
    "        # 注意尺寸是： layer_size, batch_size, hidden_size\n",
    "        # 对隐单元的初始化\n",
    "        # 对引单元输出的初始化，全0.\n",
    "        # 注意hidden和cell的维度都是layers,batch_size,hidden_size\n",
    "        hidden = Variable(torch.zeros(self.num_layers, 1, self.hidden_size))\n",
    "        # 对隐单元内部的状态cell的初始化，全0\n",
    "        cell = Variable(torch.zeros(self.num_layers, 1, self.hidden_size))\n",
    "        return (hidden, cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与之前处理得分类问题不同，在分类问题中只有最后的输出被使用。而在当前的 **生成** 姓氏的任务中，神经网络在每一步都会做预测，所以我们需要在每一步计算损失值。\n",
    "\n",
    "PyTorch 非常易用，它允许我们只是简单的把每一步计算的损失加起来，在遍历完一个姓氏后，再进行反向传播。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 你需要将训练函数补充完整，或者编写自己的训练函数。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练函数，在这个函数里，我们可以随机选择一条训练数据，遍历每个字符进行训练\n",
    "def train_LSTM():\n",
    "    # 初始化 隐藏层、梯度清零、损失清零\n",
    "    hidden = lstm.initHidden()\n",
    "#     lstm.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    # 随机选取一条训练数据\n",
    "    category_input, line_input, line_target = random_training_set()\n",
    "    # 处理国别数据\n",
    "    category_variable = Variable(torch.LongTensor([category_input]).unsqueeze(0))\n",
    "#     print('category_variable size', category_variable.size())\n",
    "    \n",
    "    # 循环字符\n",
    "    for t in range(len(line_input)):\n",
    "        # 姓氏\n",
    "        name_variable = Variable(torch.LongTensor([line_input[t]]).unsqueeze(0))\n",
    "#         print('name Variable size in Train Lstm', name_variable.size())\n",
    "        # 目标\n",
    "        target_variable = Variable(torch.LongTensor([line_target[t]]))\n",
    "        # 传入模型\n",
    "        output, hidden = lstm.forward(category_variable, name_variable, hidden)\n",
    "        # 累加损失\n",
    "#         print(output.size())\n",
    "#         print(target_variable.size())\n",
    "        loss += criterion(output, target_variable)\n",
    "    \n",
    "    # 计算平均损失\n",
    "    loss = loss / len(line_input)\n",
    "    # 反向传播、更新梯度\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward(retain_variables = True)\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们定义 `time_since` 函数，它可以打印出训练持续的时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def time_since(t):\n",
    "    now = time.time()\n",
    "    s = now - t\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**在下面你要定义损失函数、优化函数、实例化模型参数。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 10\n",
    "num_epoch = 3\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 实例化模型\n",
    "lstm =  LSTMNetwork( category_size = 18, name_size = 58, hidden_size = HIDDEN_SIZE, output_size = 59)\n",
    "# 定义损失函数与优化方法\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr = learning_rate)\n",
    "criterion = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练的过程与我们前几节课一样，都是老套路啦！\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:92: UserWarning: retain_variables option is deprecated and will be removed in 0.3. Use retain_graph instead.\n",
      "  warnings.warn(\"retain_variables option is deprecated and will be removed in 0.3. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0轮，训练损失：4.12，训练进度：0.0%，（0m 0s）\n",
      "第0轮，训练损失：2.84，训练进度：4.98%，（0m 25s）\n",
      "第0轮，训练损失：2.64，训练进度：9.96%，（0m 51s）\n",
      "第0轮，训练损失：2.55，训练进度：14.95%，（1m 16s）\n",
      "第0轮，训练损失：2.49，训练进度：19.93%，（1m 43s）\n",
      "第0轮，训练损失：2.45，训练进度：24.91%，（2m 11s）\n",
      "第0轮，训练损失：2.41，训练进度：29.89%，（2m 40s）\n",
      "第1轮，训练损失：1.74，训练进度：33.33%，（3m 4s）\n",
      "第1轮，训练损失：2.20，训练进度：38.32%，（3m 30s）\n",
      "第1轮，训练损失：2.19，训练进度：43.3%，（3m 56s）\n",
      "第1轮，训练损失：2.18，训练进度：48.28%，（4m 22s）\n",
      "第1轮，训练损失：2.18，训练进度：53.26%，（4m 48s）\n",
      "第1轮，训练损失：2.17，训练进度：58.24%，（5m 13s）\n",
      "第1轮，训练损失：2.16，训练进度：63.22%，（5m 39s）\n",
      "第2轮，训练损失：2.48，训练进度：66.67%，（6m 1s）\n",
      "第2轮，训练损失：2.13，训练进度：71.65%，（6m 27s）\n",
      "第2轮，训练损失：2.12，训练进度：76.63%，（6m 54s）\n",
      "第2轮，训练损失：2.11，训练进度：81.61%，（7m 20s）\n",
      "第2轮，训练损失：2.11，训练进度：86.59%，（7m 47s）\n",
      "第2轮，训练损失：2.11，训练进度：91.58%，（8m 15s）\n",
      "第2轮，训练损失：2.10，训练进度：96.56%，（8m 41s）\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "records = []\n",
    "# 开始训练循环\n",
    "for epoch in range(num_epoch):\n",
    "    train_loss = 0.001\n",
    "    # 按所有数据的行数随机循环\n",
    "    for i in range(all_line_num):\n",
    "        i += 1\n",
    "        loss = train_LSTM()\n",
    "        train_loss += loss\n",
    "        \n",
    "        #每隔3000步，跑一次校验集，并打印结果\n",
    "        if i % 3000 == 1:\n",
    "            training_process = (all_line_num * epoch + i) / (all_line_num * num_epoch) * 100\n",
    "            training_process = '%.2f' % training_process\n",
    "            if train_loss.data.numpy() > 0.001:\n",
    "                train_loss -= 0.001\n",
    "            print('第{}轮，训练损失：{:.2f}，训练进度：{}%，（{}）'\\\n",
    "                .format(epoch, train_loss.data.numpy()[0] / i, float(training_process), time_since(start)))\n",
    "            records.append([train_loss.data.numpy()[0] / i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绘制观察损失曲线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们将训练过程中记录的损失绘制成一条曲线，观察下神经网络学习的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1d405d591d0>"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d405d22e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "a = [i[0] for i in records]\n",
    "plt.plot(a, label = 'Train Loss')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为我在计算损失平均值时有“除0错误”，所以在损失曲线中有间断，大家可以改进我的计算方法，让损失曲线连贯起来。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试使用神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "既然神经网络训练好了，那也就是说，我们喂给它第一个字符，他就能生成第二个字符，喂给它第二个字符，它就会生成第三个，这样一直持续下去，直至生成 EOS 才结束。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那下面我们编写 `generate_one` 函数以方便的使用神经网络生成我们想要的名字字符串，在这个函数里我们定义以下内容：\n",
    "\n",
    "* 建立输入国别，开始字符，初始隐藏层状态的 Tensor\n",
    "* 创建 `output_str` 变量，创建时其中只包含“开始字符”\n",
    "* 定义生成名字的长度最大不超过 `max_length`\n",
    "    * 将当前字符传入神经网络\n",
    "    * 在输出中选出预测的概率最大的下一个字符，同时取出当前的隐藏层状态\n",
    "    * 如果字符是 EOS，则生成结束\n",
    "    * 如果是常规字符，则加入到 `output_str` 中并继续下一个流程\n",
    "* 返回最终生成的名字字符串"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 你需要自行编写模型验证方法。 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_length = 20\n",
    "\n",
    "# 通过指定国别名 category\n",
    "# 以及开始字符 start_char\n",
    "# 还有混乱度 temperature 来生成一个名字\n",
    "def generate_one(category, start_char='A', temperature=0.2):\n",
    "    # 初始化输入数据，国别 以及 输入的第一个字符\n",
    "    # 国别\n",
    "#     make_category_input(category)\n",
    "    category_input = make_category_input(random.choice(all_categories))\n",
    "    print(category_input)\n",
    "    category_variable = Variable(torch.LongTensor([category_input]).unsqueeze(0))\n",
    "    # 第一个字符\n",
    "#     start_char = random.choice(all_letters)\n",
    "    char_variable = Variable(torch.LongTensor([make_chars_input(start_char)]))\n",
    "    # 初始化隐藏层\n",
    "    hidden = lstm.initHidden()\n",
    "\n",
    "    output_str = start_char\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        \n",
    "        # 调用模型\n",
    "        output, hidden = lstm(category_variable, char_variable, hidden)\n",
    "        \n",
    "        # 这里是将输出转化为一个多项式分布\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        # 从而可以根据混乱度 temperature 来选择下一个字符\n",
    "        # 混乱度低，则趋向于选择网络预测最大概率的那个字符\n",
    "        # 混乱度高，则趋向于随机选择字符\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # 生成字符是 EOS，则生成结束\n",
    "        if top_i == EOS:\n",
    "            break\n",
    "        else:\n",
    "            # 继续下一个字符\n",
    "            char = all_letters[top_i]\n",
    "            output_str += char\n",
    "            chars_input = make_chars_input(char)\n",
    "            name_variable = Variable(torch.LongTensor([chars_input]))\n",
    "            \n",
    "    return output_str\n",
    "\n",
    "# 再定义一个函数，方便每次生成多个名字\n",
    "def generate(category, start_chars='ABC'):\n",
    "    for start_char in start_chars:\n",
    "        print(generate_one(category, start_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Raaaaeeaaeaeeeaaaaeea\n",
      "14\n",
      "Uvvnnkklkk\n",
      "12\n",
      "Saauaiaiiuiiiiaaiiiii\n"
     ]
    }
   ],
   "source": [
    "generate('Russian', 'RUS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Geeeeeee\n",
      "16\n",
      "Elsssssssssssssssssss\n",
      "8\n",
      "Raooa\n"
     ]
    }
   ],
   "source": [
    "generate('German', 'GER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Shaaccciiaaaoiaiaioaa\n",
      "17\n",
      "Phoaoaaaaaoooaaoaaoaa\n",
      "12\n",
      "Alrlnrlrtnlllllnlnnrl\n"
     ]
    }
   ],
   "source": [
    "generate('Spanish', 'SPA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Cheaeeeeaeeeaeeeeeeee\n",
      "13\n",
      "Haeeeaeeeeeeeeeeeaeee\n",
      "14\n",
      "Ivnv\n"
     ]
    }
   ],
   "source": [
    "generate('Chinese', 'CHI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到 LSTM 预测的效果，但显然还不理想，我想你可以通过调整网络模型，或者通过调整超参数让模型表现的更好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://wiki.swarma.net/images/c/ca/AI学园.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "nbpresent": {
   "slides": {
    "10393c05-7962-4245-9228-8b7db4eb79a1": {
     "id": "10393c05-7962-4245-9228-8b7db4eb79a1",
     "prev": "22628fc4-8309-4579-ba36-e5b01a841473",
     "regions": {
      "335fd672-4ee6-4b7c-a65f-3ecbf38305e1": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "cc294dae-dd8f-4288-8d3c-bb9fd3ad19bc",
        "part": "whole"
       },
       "id": "335fd672-4ee6-4b7c-a65f-3ecbf38305e1"
      }
     }
    },
    "22628fc4-8309-4579-ba36-e5b01a841473": {
     "id": "22628fc4-8309-4579-ba36-e5b01a841473",
     "prev": null,
     "regions": {
      "6cfa5157-02f6-48e3-8ce4-89641febbe59": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "9a73330c-27c1-4957-8e95-c3b42bc14a71",
        "part": "whole"
       },
       "id": "6cfa5157-02f6-48e3-8ce4-89641febbe59"
      }
     }
    },
    "2f34f0df-3ccc-4416-9d5d-cb4b075f539f": {
     "id": "2f34f0df-3ccc-4416-9d5d-cb4b075f539f",
     "prev": "3eb7f63f-04de-4f51-a240-38d5074bed6f",
     "regions": {
      "e25707b9-630e-4ece-9f66-bfcbc8342d76": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "df50f546-6d02-4383-beab-90378f16576b",
        "part": "whole"
       },
       "id": "e25707b9-630e-4ece-9f66-bfcbc8342d76"
      }
     }
    },
    "3eb7f63f-04de-4f51-a240-38d5074bed6f": {
     "id": "3eb7f63f-04de-4f51-a240-38d5074bed6f",
     "prev": "cc4bd43a-59ec-4127-b1d8-ebd30162207a",
     "regions": {
      "76282c28-a6ba-4a08-be6c-4f27f5b81ddf": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "53fb987f-4f42-4bf8-81ae-280ebdd19aee",
        "part": "whole"
       },
       "id": "76282c28-a6ba-4a08-be6c-4f27f5b81ddf"
      }
     }
    },
    "686bcaec-0623-4943-b227-f4e1c5975c4a": {
     "id": "686bcaec-0623-4943-b227-f4e1c5975c4a",
     "prev": "e4c6fc30-f833-4368-99fe-5297b99f1f14",
     "regions": {
      "659c021e-7f79-4612-aa7d-8f1c48f91f8b": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4ff5f52a-2523-47f0-beba-f6c29d412e5f",
        "part": "whole"
       },
       "id": "659c021e-7f79-4612-aa7d-8f1c48f91f8b"
      }
     }
    },
    "964ac1b6-c781-47e8-89f0-1f593d473cd0": {
     "id": "964ac1b6-c781-47e8-89f0-1f593d473cd0",
     "prev": "cf8a3b4c-bbb5-4ef3-a8c6-43a1ad7eebc8",
     "regions": {
      "d22afc7e-4bbe-401e-9bd2-d12c4a103cf5": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "8ff6da45-57cd-46ca-b14a-3f560ce4d345",
        "part": "whole"
       },
       "id": "d22afc7e-4bbe-401e-9bd2-d12c4a103cf5"
      }
     }
    },
    "cc4bd43a-59ec-4127-b1d8-ebd30162207a": {
     "id": "cc4bd43a-59ec-4127-b1d8-ebd30162207a",
     "prev": "964ac1b6-c781-47e8-89f0-1f593d473cd0",
     "regions": {
      "1e6711af-7711-4579-ac7a-f893b0d86931": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "cf311809-10bf-40f7-87e1-1952342f7f35",
        "part": "whole"
       },
       "id": "1e6711af-7711-4579-ac7a-f893b0d86931"
      }
     }
    },
    "cf8a3b4c-bbb5-4ef3-a8c6-43a1ad7eebc8": {
     "id": "cf8a3b4c-bbb5-4ef3-a8c6-43a1ad7eebc8",
     "prev": "686bcaec-0623-4943-b227-f4e1c5975c4a",
     "regions": {
      "3b983e72-35fb-4d19-83b4-789a3394f61f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "597a765d-634b-41a8-a0c6-be5c019da150",
        "part": "whole"
       },
       "id": "3b983e72-35fb-4d19-83b4-789a3394f61f"
      }
     }
    },
    "e4c6fc30-f833-4368-99fe-5297b99f1f14": {
     "id": "e4c6fc30-f833-4368-99fe-5297b99f1f14",
     "prev": "10393c05-7962-4245-9228-8b7db4eb79a1",
     "regions": {
      "98a6b3b6-d2db-4d8a-bb16-a4307ede4803": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "6a9d80df-1d38-4c41-849c-95e38da98cc7",
        "part": "whole"
       },
       "id": "98a6b3b6-d2db-4d8a-bb16-a4307ede4803"
      }
     }
    },
    "f1a487d8-4b0b-47df-988f-1161d66174b2": {
     "id": "f1a487d8-4b0b-47df-988f-1161d66174b2",
     "prev": "2f34f0df-3ccc-4416-9d5d-cb4b075f539f",
     "regions": {
      "2c817a32-203d-404b-8bf5-ba17f7d27034": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "81fde336-785e-461b-a751-718a5f6bff88",
        "part": "whole"
       },
       "id": "2c817a32-203d-404b-8bf5-ba17f7d27034"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
