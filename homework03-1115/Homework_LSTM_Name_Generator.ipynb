{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://wiki.swarma.net/images/e/e7/集智AI学园首页左上角logo_2017.8.17.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 火炬上的深度学习（下）第三节：神经网络莫扎特"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 课后作业：使用 LSTM 编写一个国际姓氏生成模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在火炬课程中，我们学习了使用 LSTM 来生成 MIDI 音乐。这节课我们使用类似的方法，再创建一个 LSTM 国际起名大师！\n",
    "\n",
    "完成后的模型能够像下面这样使用，指定一个国家名，模型即生成几个属于这个国家的姓氏。\n",
    "\n",
    "```\n",
    "> python generate.py Russian\n",
    "Rovakov    Uantov    Shavakov\n",
    "\n",
    "> python generate.py German\n",
    "Gerren    Ereng    Rosher\n",
    "\n",
    "> python generate.py Spanish\n",
    "Salla    Parer    Allan\n",
    "\n",
    "> python generate.py Chinese\n",
    "Chan    Hang    Iun\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 第一步当然是引入PyTorch及相关包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "这次的数据仍然是18个文本文件，每个文件以“国家名字”命名，文件中存储了大量这个国家的姓氏。\n",
    "\n",
    "在读取这些数据前，为了简化神经网络的输入参数规模，我们把各国各语言人名都转化成用26个英文字母来表示，下面就是转换的方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "6a9d80df-1d38-4c41-849c-95e38da98cc7"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O'Neal\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "# all_letters 即课支持打印的字符+标点符号\n",
    "all_letters = string.ascii_letters + \" .,;'-\"\n",
    "# Plus EOS marker\n",
    "n_letters = len(all_letters) + 1 \n",
    "EOS = n_letters - 1\n",
    "\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "print(unicode_to_ascii(\"O'Néàl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到 `\"O'Néàl\"` 被转化成了以普通ASCII字符表示的 `O'Neal`。\n",
    "\n",
    "在上面的代码中，还要注意这么几个变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_letters:  abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .,;'-\n",
      "n_letters:  59\n",
      "EOS:  58\n"
     ]
    }
   ],
   "source": [
    "# 姓氏中所有的可视字符\n",
    "print('all_letters: ', all_letters)\n",
    "# 所有字符的长度 +1 EOS结束符\n",
    "print('n_letters: ', n_letters)\n",
    "# 结束符，没有实质内容\n",
    "print('EOS: ', EOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中 `all_letters` 包含了我们数据集中所有可能出现的字符，也就是“字符表”。\n",
    "`n_letters` 是字符表的长度，在本例中长度为59。`EOS` 的索引号为58，它在字符表中没有对应的字符，仅代表结束。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备好处理数据的方法，下面就可以放心的读取数据了。\n",
    "\n",
    "我们建立一个列表 `all_categories` 用于存储所有的国家名字。\n",
    "\n",
    "建立一个字典 `category_lines`，以读取的国名作为字典的索引，国名下存储对应国别的名字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# categories:  18 ['Arabic', 'Chinese', 'Czech', 'Dutch', 'English', 'French', 'German', 'Greek', 'Irish', 'Italian', 'Japanese', 'Korean', 'Polish', 'Portuguese', 'Russian', 'Scottish', 'Spanish', 'Vietnamese']\n",
      "\n",
      "# Russian names:  ['Ababko', 'Abaev', 'Abagyan', 'Abaidulin', 'Abaidullin', 'Abaimoff', 'Abaimov', 'Abakeliya', 'Abakovsky', 'Abakshin']\n"
     ]
    }
   ],
   "source": [
    "# 按行读取出文件中的名字，并返回包含所有名字的列表\n",
    "def read_lines(filename):\n",
    "    lines = open(filename).read().strip().split('\\n')\n",
    "    return [unicode_to_ascii(line) for line in lines]\n",
    "\n",
    "\n",
    "# category_lines是一个字典\n",
    "# 其中索引是国家名字，内容是从文件读取出的这个国家的所有名字\n",
    "category_lines = {}\n",
    "# all_categories是一个列表\n",
    "# 其中包含了所有的国家名字\n",
    "all_categories = []\n",
    "# 循环所有文件\n",
    "for filename in glob.glob('./names/*.txt'):\n",
    "    # 从文件名中切割出国家名字\n",
    "    category = filename.split('/')[-1].split('.')[0].split('\\\\')[-1]\n",
    "    # 将国家名字添加到列表中\n",
    "    all_categories.append(category)\n",
    "    # 读取对应国别文件中所有的名字\n",
    "    lines = read_lines(filename)\n",
    "    # 将所有名字存储在字典中对应的国别下\n",
    "    category_lines[category] = lines\n",
    "\n",
    "# 共有的国别数\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "print('# categories: ', n_categories, all_categories)\n",
    "print()\n",
    "print('# Russian names: ', category_lines['Russian'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20074\n"
     ]
    }
   ],
   "source": [
    "# 再统计下手头共有多少条训练数据\n",
    "all_line_num = 0\n",
    "for key in category_lines:\n",
    "    all_line_num += len(category_lines[key])\n",
    "print(all_line_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们的数据准备好了，可以搭建神经网络了！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先建立一个可以随机选择数据对 `(category, line)` 的方法，以方便训练时调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('English', 'Tipping')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def random_training_pair():\n",
    "    # 随机选择一个国别名\n",
    "    category = random.choice(all_categories)\n",
    "    # 读取这个国别名下的所有人名\n",
    "    line = random.choice(category_lines[category])\n",
    "    return category, line\n",
    "\n",
    "print(random_training_pair())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先处理国别，将国别名转化为索引。\n",
    "\n",
    "这个索引是要和姓氏一起传入神经网络模型的。我们这次编写的是根据“国名条件”生成“符合条件的姓氏”的 LSTM 模型。这种将“条件”和“符合条件的数据”合并一起作为训练输入数据的方法，在“条件模型”里非常流行。\n",
    "\n",
    "比如 条件GAN（Conditional GAN），在训练时是把数据标签拼接到数据图片中一起进行训练的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# 将名字所属的国家名转化为“独热向量”\n",
    "def make_category_input(category):\n",
    "    li = all_categories.index(category)\n",
    "    return  li\n",
    "\n",
    "print(make_category_input('Italian'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "对于训练过程中的每一步，或者说对于训练数据中每个名字的每个字符来说，神经网络的输入是 `(category, current letter, hidden state)`，输出是 `(next letter, next hidden state)`。\n",
    "\n",
    "与在课程中讲的一样，神经网络还是依据“当前的字符”预测“下一个字符”。比如对于“Kasparov”这个名字，创建的（input, target）数据对是 (\"K\", \"a\"), (\"a\", \"s\"), (\"s\", \"p\"), (\"p\", \"a\"), (\"a\", \"r\"), (\"r\", \"o\"), (\"o\", \"v\"), (\"v\", \"EOS\")。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "cf311809-10bf-40f7-87e1-1952342f7f35"
    }
   },
   "outputs": [],
   "source": [
    "def make_chars_input(nameStr):\n",
    "    name_char_list = list(map(lambda x: all_letters.find(x), nameStr))\n",
    "    return name_char_list\n",
    "\n",
    "\n",
    "def make_target(nameStr):\n",
    "    target_char_list = list(map(lambda x: all_letters.find(x), nameStr[1:]))\n",
    "    target_char_list.append(n_letters - 1)# EOS\n",
    "    return target_char_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样为了训练时方便使用，我们建立一个 `random_training_set` 函数，以随机选择出数据集 `(category, line)` 并转化成训练需要的 Tensor： `(category, input, target) `。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_training_set():\n",
    "    # 随机选择数据集\n",
    "    category, line = random_training_pair()\n",
    "    #print(category, line)\n",
    "    # 转化成对应 Tensor\n",
    "    category_input = make_category_input(category)\n",
    "    line_input = make_chars_input(line)\n",
    "    #category_name_input = make_category_name_input(category, line)\n",
    "    line_target = make_target(line)\n",
    "    return category_input, line_input, line_target\n",
    "    #return category_name_input, line_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, [36, 0, 15, 15, 4, 11], [0, 15, 15, 4, 11, 58])\n"
     ]
    }
   ],
   "source": [
    "print(random_training_set())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4ff5f52a-2523-47f0-beba-f6c29d412e5f"
    }
   },
   "source": [
    "# 搭建神经网络\n",
    "\n",
    "这次使用的 LSTM 神经网络整体结构上与课上讲的生成音乐的模型非常相似，不过有一点请注意一下。\n",
    "\n",
    "我们要把国别和国别对应的姓氏一同输入到神经网络中，这样 LSTM 模型才能分别学习到每个国家姓氏的特色，从而生成不同国家不同特色的姓氏。\n",
    "\n",
    "那国别数据与姓氏数据应该如何拼接哪？应该在嵌入前拼接，还是在嵌入后再进行拼接哪？嵌入后的维度与 hidden_size 有怎样的关系哪？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 你需要参考课上的模型，将这个模型补充完整。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 一个手动实现的LSTM模型，\n",
    "\n",
    "class LSTMNetwork(nn.Module):\n",
    "    def __init__(self, category_size, name_size, hidden_size, output_size, num_layers = 1):\n",
    "        super(LSTMNetwork, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "       \n",
    "        # 进行嵌入\n",
    "        self.Embedding_category = nn.Embedding(category_size, hidden_size)\n",
    "        self.Embedding_name = nn.Embedding(name_size, hidden_size)\n",
    "        \n",
    "        # 隐含层内部的相互链接\n",
    "        \n",
    "        self.lstm = nn.LSTM(2 * hidden_size, hidden_size, num_layers, batch_first = True)\n",
    "        \n",
    "        self.FC = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        # 输出层\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, category_variable, name_variable, hidden):\n",
    "        \n",
    "        # 先分别进行embedding层的计算\n",
    "#         print('category_variable size', category_variable.size())\n",
    "        category_embedded = self.Embedding_category(category_variable)\n",
    "#         print('name_variable size', name_variable.size())\n",
    "        name_embedded = self.Embedding_name(name_variable)\n",
    "        \n",
    "#         print('category_embedded size before cat: ', category_embedded.size())\n",
    "#         print('name embedded size before cat:', name_embedded.size())\n",
    "        temp = torch.cat( [category_embedded, name_embedded]).view(self.hidden_size*2,-1)\n",
    "        \n",
    "#         print('temp', temp)\n",
    "        \n",
    "        output, hidden = self.lstm(temp, hidden)\n",
    "#         print('size before', output.size())\n",
    "        output = output[:,-1,:]\n",
    "        # 从输入到隐含层的计算\n",
    "#         print('size after', output.size())\n",
    "        # output的尺寸：batch_size, len_seq, hidden_size\n",
    "        \n",
    "        # 全连接层\n",
    "        output = self.FC(output)\n",
    "        # output的尺寸：batch_size, output_size\n",
    "        # softmax函数\n",
    "        output = self.softmax(output)\n",
    "#         print('before print', output.size())\n",
    "        return output, hidden\n",
    " \n",
    "    def initHidden(self):\n",
    "        # 对隐含单元的初始化\n",
    "        # 注意尺寸是： layer_size, batch_size, hidden_size\n",
    "        # 对隐单元的初始化\n",
    "        # 对引单元输出的初始化，全0.\n",
    "        # 注意hidden和cell的维度都是layers,batch_size,hidden_size\n",
    "        hidden = Variable(torch.zeros(self.num_layers, 1, self.hidden_size))\n",
    "        # 对隐单元内部的状态cell的初始化，全0\n",
    "        cell = Variable(torch.zeros(self.num_layers, 1, self.hidden_size))\n",
    "        return (hidden, cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与之前处理得分类问题不同，在分类问题中只有最后的输出被使用。而在当前的 **生成** 姓氏的任务中，神经网络在每一步都会做预测，所以我们需要在每一步计算损失值。\n",
    "\n",
    "PyTorch 非常易用，它允许我们只是简单的把每一步计算的损失加起来，在遍历完一个姓氏后，再进行反向传播。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 你需要将训练函数补充完整，或者编写自己的训练函数。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义训练函数，在这个函数里，我们可以随机选择一条训练数据，遍历每个字符进行训练\n",
    "def train_LSTM(lstm):\n",
    "    # 初始化 隐藏层、梯度清零、损失清零\n",
    "    hidden = lstm.initHidden()\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    # 随机选取一条训练数据\n",
    "    category_input, line_input, line_target = random_training_set()\n",
    "    # 处理国别数据\n",
    "    category_variable = Variable(torch.LongTensor([category_input]))\n",
    "#     print('category_variable size', category_variable.size())\n",
    "    \n",
    "    # 循环字符\n",
    "    for t in range(len(line_input)):\n",
    "        # 姓氏\n",
    "        name_variable = Variable(torch.LongTensor([line_input[t]]))\n",
    "#         print('name Variable size in Train Lstm', name_variable.size())\n",
    "        # 目标\n",
    "        target_variable = Variable(torch.LongTensor([line_target[t]]))\n",
    "        # 传入模型\n",
    "        output, hidden = lstm(category_variable, name_variable, hidden)\n",
    "        # 累加损失\n",
    "#         print(output.size())\n",
    "#         print(target_variable.size())\n",
    "        loss += criterion(output, target_variable)\n",
    "    \n",
    "    # 计算平均损失\n",
    "    loss = 1.0 * loss / len(line_input)\n",
    "    # 反向传播、更新梯度\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们定义 `time_since` 函数，它可以打印出训练持续的时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def time_since(t):\n",
    "    now = time.time()\n",
    "    s = now - t\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**在下面你要定义损失函数、优化函数、实例化模型参数。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 32\n",
    "num_epoch = 3\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 实例化模型\n",
    "lstm =  LSTMNetwork( category_size = 18, name_size = 58, hidden_size = HIDDEN_SIZE, output_size = 59)\n",
    "# 定义损失函数与优化方法\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr = learning_rate)\n",
    "criterion = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练的过程与我们前几节课一样，都是老套路啦！\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0轮，训练损失：4.12，训练进度：0.0%，（0m 0s）\n",
      "第0轮，训练损失：2.52，训练进度：4.98%，（0m 28s）\n",
      "第0轮，训练损失：2.34，训练进度：9.96%，（0m 57s）\n",
      "第0轮，训练损失：2.25，训练进度：14.95%，（1m 31s）\n",
      "第0轮，训练损失：2.19，训练进度：19.93%，（2m 5s）\n",
      "第0轮，训练损失：2.14，训练进度：24.91%，（2m 37s）\n",
      "第0轮，训练损失：2.10，训练进度：29.89%，（3m 7s）\n",
      "第1轮，训练损失：1.00，训练进度：33.33%，（3m 33s）\n",
      "第1轮，训练损失：1.86，训练进度：38.32%，（4m 1s）\n",
      "第1轮，训练损失：1.84，训练进度：43.3%，（4m 30s）\n",
      "第1轮，训练损失：1.83，训练进度：48.28%，（4m 59s）\n",
      "第1轮，训练损失：1.82，训练进度：53.26%，（5m 29s）\n",
      "第1轮，训练损失：1.82，训练进度：58.24%，（6m 0s）\n",
      "第1轮，训练损失：1.81，训练进度：63.22%，（6m 33s）\n",
      "第2轮，训练损失：2.10，训练进度：66.67%，（7m 2s）\n",
      "第2轮，训练损失：1.74，训练进度：71.65%，（7m 32s）\n",
      "第2轮，训练损失：1.73，训练进度：76.63%，（8m 3s）\n",
      "第2轮，训练损失：1.72，训练进度：81.61%，（8m 36s）\n",
      "第2轮，训练损失：1.71，训练进度：86.59%，（9m 7s）\n",
      "第2轮，训练损失：1.70，训练进度：91.58%，（9m 40s）\n",
      "第2轮，训练损失：1.69，训练进度：96.56%，（10m 13s）\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "records = []\n",
    "# 开始训练循环\n",
    "for epoch in range(num_epoch):\n",
    "    train_loss = 0.001\n",
    "    # 按所有数据的行数随机循环\n",
    "    for i in range(all_line_num):\n",
    "        i += 1\n",
    "        loss = train_LSTM(lstm)\n",
    "        train_loss += loss\n",
    "        \n",
    "        #每隔3000步，跑一次校验集，并打印结果\n",
    "        if i % 3000 == 1:\n",
    "            training_process = (all_line_num * epoch + i) / (all_line_num * num_epoch) * 100\n",
    "            training_process = '%.2f' % training_process\n",
    "#             if train_loss.data.numpy() > 0.001:\n",
    "#                 train_loss -= 0.001\n",
    "            print('第{}轮，训练损失：{:.2f}，训练进度：{}%，（{}）'\\\n",
    "                .format(epoch, train_loss.data.numpy()[0] / i, float(training_process), time_since(start)))\n",
    "            records.append([train_loss.data.numpy()[0] / i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绘制观察损失曲线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们将训练过程中记录的损失绘制成一条曲线，观察下神经网络学习的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2bae43e60b8>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ba81078198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "a = [i[0] for i in records]\n",
    "plt.plot(a, label = 'Train Loss')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为我在计算损失平均值时有“除0错误”，所以在损失曲线中有间断，大家可以改进我的计算方法，让损失曲线连贯起来。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试使用神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "既然神经网络训练好了，那也就是说，我们喂给它第一个字符，他就能生成第二个字符，喂给它第二个字符，它就会生成第三个，这样一直持续下去，直至生成 EOS 才结束。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那下面我们编写 `generate_one` 函数以方便的使用神经网络生成我们想要的名字字符串，在这个函数里我们定义以下内容：\n",
    "\n",
    "* 建立输入国别，开始字符，初始隐藏层状态的 Tensor\n",
    "* 创建 `output_str` 变量，创建时其中只包含“开始字符”\n",
    "* 定义生成名字的长度最大不超过 `max_length`\n",
    "    * 将当前字符传入神经网络\n",
    "    * 在输出中选出预测的概率最大的下一个字符，同时取出当前的隐藏层状态\n",
    "    * 如果字符是 EOS，则生成结束\n",
    "    * 如果是常规字符，则加入到 `output_str` 中并继续下一个流程\n",
    "* 返回最终生成的名字字符串"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 你需要自行编写模型验证方法。 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_length = 20\n",
    "\n",
    "# 通过指定国别名 category\n",
    "# 以及开始字符 start_char\n",
    "# 还有混乱度 temperature 来生成一个名字\n",
    "def generate_one(category, start_char='A', temperature=0.2):\n",
    "    # 初始化输入数据，国别 以及 输入的第一个字符\n",
    "    # 国别\n",
    "#     make_category_input(category)\n",
    "#     category_input = make_category_input(random.choice(all_categories))   ### \n",
    "    category_input = make_category_input(category)\n",
    "#     print('category input size', category_input.size())\n",
    "    category_variable = Variable(torch.LongTensor([category_input]))\n",
    "    # 第一个字符\n",
    "#     print('category_variable size', category_variable.size())\n",
    "    \n",
    "    char_idx = all_letters.index(start_char)\n",
    "    char_variable = Variable(torch.LongTensor([char_idx]))\n",
    "#     print('char variable size', char_variable.size())\n",
    "#     name_idx = all_letters.index(start_char)\n",
    "#     name_variable = Variable(torch.LongTensor([name_idx]))\n",
    "    # 初始化隐藏层\n",
    "    hidden = lstm.initHidden()\n",
    "\n",
    "    output_str = start_char\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        \n",
    "        # 调用模型\n",
    "        output, hidden = lstm(category_variable, char_variable, hidden)\n",
    "        \n",
    "        # 这里是将输出转化为一个多项式分布\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        # 从而可以根据混乱度 temperature 来选择下一个字符\n",
    "        # 混乱度低，则趋向于选择网络预测最大概率的那个字符\n",
    "        # 混乱度高，则趋向于随机选择字符\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # 生成字符是 EOS，则生成结束\n",
    "        if top_i == EOS:\n",
    "            break\n",
    "        else:\n",
    "            # 继续下一个字符\n",
    "            char = all_letters[top_i]\n",
    "            output_str += char\n",
    "            chars_input = all_letters.index(char)\n",
    "            char_variable = Variable(torch.LongTensor([chars_input]))\n",
    "            \n",
    "    return output_str\n",
    "\n",
    "# 再定义一个函数，方便每次生成多个名字\n",
    "def generate(category, start_chars='ABC'):\n",
    "    for start_char in start_chars:\n",
    "        print(generate_one(category, start_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rukhev\n",
      "Uthin\n",
      "Shalkov\n"
     ]
    }
   ],
   "source": [
    "generate('Russian', 'RUS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grors\n",
      "Ester\n",
      "Ras\n"
     ]
    }
   ],
   "source": [
    "generate('German', 'GER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Santo\n",
      "Pello\n",
      "Arajo\n"
     ]
    }
   ],
   "source": [
    "generate('Spanish', 'SPA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chu\n",
      "Hui\n",
      "Iwang\n"
     ]
    }
   ],
   "source": [
    "generate('Chinese', 'CHI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到 LSTM 预测的效果，但显然还不理想，我想你可以通过调整网络模型，或者通过调整超参数让模型表现的更好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://wiki.swarma.net/images/c/ca/AI学园.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "nbpresent": {
   "slides": {
    "10393c05-7962-4245-9228-8b7db4eb79a1": {
     "id": "10393c05-7962-4245-9228-8b7db4eb79a1",
     "prev": "22628fc4-8309-4579-ba36-e5b01a841473",
     "regions": {
      "335fd672-4ee6-4b7c-a65f-3ecbf38305e1": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "cc294dae-dd8f-4288-8d3c-bb9fd3ad19bc",
        "part": "whole"
       },
       "id": "335fd672-4ee6-4b7c-a65f-3ecbf38305e1"
      }
     }
    },
    "22628fc4-8309-4579-ba36-e5b01a841473": {
     "id": "22628fc4-8309-4579-ba36-e5b01a841473",
     "prev": null,
     "regions": {
      "6cfa5157-02f6-48e3-8ce4-89641febbe59": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "9a73330c-27c1-4957-8e95-c3b42bc14a71",
        "part": "whole"
       },
       "id": "6cfa5157-02f6-48e3-8ce4-89641febbe59"
      }
     }
    },
    "2f34f0df-3ccc-4416-9d5d-cb4b075f539f": {
     "id": "2f34f0df-3ccc-4416-9d5d-cb4b075f539f",
     "prev": "3eb7f63f-04de-4f51-a240-38d5074bed6f",
     "regions": {
      "e25707b9-630e-4ece-9f66-bfcbc8342d76": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "df50f546-6d02-4383-beab-90378f16576b",
        "part": "whole"
       },
       "id": "e25707b9-630e-4ece-9f66-bfcbc8342d76"
      }
     }
    },
    "3eb7f63f-04de-4f51-a240-38d5074bed6f": {
     "id": "3eb7f63f-04de-4f51-a240-38d5074bed6f",
     "prev": "cc4bd43a-59ec-4127-b1d8-ebd30162207a",
     "regions": {
      "76282c28-a6ba-4a08-be6c-4f27f5b81ddf": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "53fb987f-4f42-4bf8-81ae-280ebdd19aee",
        "part": "whole"
       },
       "id": "76282c28-a6ba-4a08-be6c-4f27f5b81ddf"
      }
     }
    },
    "686bcaec-0623-4943-b227-f4e1c5975c4a": {
     "id": "686bcaec-0623-4943-b227-f4e1c5975c4a",
     "prev": "e4c6fc30-f833-4368-99fe-5297b99f1f14",
     "regions": {
      "659c021e-7f79-4612-aa7d-8f1c48f91f8b": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4ff5f52a-2523-47f0-beba-f6c29d412e5f",
        "part": "whole"
       },
       "id": "659c021e-7f79-4612-aa7d-8f1c48f91f8b"
      }
     }
    },
    "964ac1b6-c781-47e8-89f0-1f593d473cd0": {
     "id": "964ac1b6-c781-47e8-89f0-1f593d473cd0",
     "prev": "cf8a3b4c-bbb5-4ef3-a8c6-43a1ad7eebc8",
     "regions": {
      "d22afc7e-4bbe-401e-9bd2-d12c4a103cf5": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "8ff6da45-57cd-46ca-b14a-3f560ce4d345",
        "part": "whole"
       },
       "id": "d22afc7e-4bbe-401e-9bd2-d12c4a103cf5"
      }
     }
    },
    "cc4bd43a-59ec-4127-b1d8-ebd30162207a": {
     "id": "cc4bd43a-59ec-4127-b1d8-ebd30162207a",
     "prev": "964ac1b6-c781-47e8-89f0-1f593d473cd0",
     "regions": {
      "1e6711af-7711-4579-ac7a-f893b0d86931": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "cf311809-10bf-40f7-87e1-1952342f7f35",
        "part": "whole"
       },
       "id": "1e6711af-7711-4579-ac7a-f893b0d86931"
      }
     }
    },
    "cf8a3b4c-bbb5-4ef3-a8c6-43a1ad7eebc8": {
     "id": "cf8a3b4c-bbb5-4ef3-a8c6-43a1ad7eebc8",
     "prev": "686bcaec-0623-4943-b227-f4e1c5975c4a",
     "regions": {
      "3b983e72-35fb-4d19-83b4-789a3394f61f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "597a765d-634b-41a8-a0c6-be5c019da150",
        "part": "whole"
       },
       "id": "3b983e72-35fb-4d19-83b4-789a3394f61f"
      }
     }
    },
    "e4c6fc30-f833-4368-99fe-5297b99f1f14": {
     "id": "e4c6fc30-f833-4368-99fe-5297b99f1f14",
     "prev": "10393c05-7962-4245-9228-8b7db4eb79a1",
     "regions": {
      "98a6b3b6-d2db-4d8a-bb16-a4307ede4803": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "6a9d80df-1d38-4c41-849c-95e38da98cc7",
        "part": "whole"
       },
       "id": "98a6b3b6-d2db-4d8a-bb16-a4307ede4803"
      }
     }
    },
    "f1a487d8-4b0b-47df-988f-1161d66174b2": {
     "id": "f1a487d8-4b0b-47df-988f-1161d66174b2",
     "prev": "2f34f0df-3ccc-4416-9d5d-cb4b075f539f",
     "regions": {
      "2c817a32-203d-404b-8bf5-ba17f7d27034": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "81fde336-785e-461b-a751-718a5f6bff88",
        "part": "whole"
       },
       "id": "2c817a32-203d-404b-8bf5-ba17f7d27034"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
